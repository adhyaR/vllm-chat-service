# vLLM backend service URL
VLLM_URL=http://127.0.0.1:8000/v1

# Model identifier (for reference, as mentioned in README)
MODEL_ID=TinyLlama/TinyLlama-1.1B-Chat-v1.0

# Logging level (DEBUG, INFO, WARNING, ERROR, CRITICAL)
LOG_LEVEL=INFO
