# vllm-chat-service
A lightweight FastAPI microservice that wraps a local vLLM instance to provide instant chat completions. Includes request validation, testing and CI/CD for clean and reproducible evaluation. 
